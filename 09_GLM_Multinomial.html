<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Masanao Yajima" />

<meta name="date" content="2018-10-13" />

<meta name="progressive" content="false" />
<meta name="allow-skip" content="false" />

<title>Multinomial Regression</title>


<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>



<div class="pageContent band">
<div class="bandContent page">

<div class="topics">

<div id="section-introduction" class="section level2">
<h2>Introduction</h2>
<ul>
<li>Categorical outcomes are encountered often in practice and is a generalization of a biomial outcome. Example of such include
<ul>
<li>Surveys with likert scale,</li>
<li>customer ratings on review website,</li>
<li>political beliefs,</li>
<li>Distribution of eye color of 100 babies born in a certain state,</li>
<li>Number of genes a cell expresses under certain condition.</li>
<li>Number of words used in an article for certain topic in Wikipedia, etc.</li>
</ul></li>
<li><p>People often choose categorical outcome for various reasons including convenience. However, what many people realize after getting the data is that the analysis of categorical outcome is much more complicated compared to a linear regression or even a logistic regression.</p></li>
<li><p>Going through this set of tutorials, you will also notice very quickly that interpreting a categorical regression model is not easy, if you can interpret them at all. Let me assure you that this is not a because you’ve failed to keep up, rather it is <em>really</em> difficult.</p></li>
<li><p>Categorical regression models are the first of multivariate outcomes models that you will encounter in this program. This tutorial will go into many details, especially for this topic, since it is not covered much in the text books. So please try to not get discouraged.</p></li>
</ul>
<div id="section-glm-for-categorical-response" class="section level3">
<h3>GLM for categorical response</h3>
<ul>
<li>There are two types of categorical variables that we will consider.
<ol style="list-style-type: decimal">
<li>Nominal: no natural order among the response categories
<ul>
<li>Butterfly types</li>
<li>Different words</li>
<li>Race/Ethnicity</li>
</ul></li>
<li>Ordinal: natural order among the response categories
<ul>
<li>number of stars on restaurant review site</li>
<li>Yes/Maybe/No, True/Indifferent/False</li>
<li>Likert Scale: Strongly Agree/Agree/Neutral/Disagree/Strongly Disagree</li>
</ul></li>
</ol></li>
<li>Depending on which type of variable we are considering, the choice of models we use will be slightly different. Therefore, it is important to understand the distinctions. At the same time, there are situations where it can be argued both ways. The rule of thumb is that if it is contextually feasible to treat the problem as an ordinal variable problem, it’s better to do so.</li>
</ul>

<div id="htmlwidget-d9e88744a0d44cd7efb6" style="width:100%;height:auto;", class = "quiz html-widget">
<div class="panel panel-default">
<div class="panel-body quizArea">
</div>
</div>
</div>

<script type="application/json" data-for="htmlwidget-d9e88744a0d44cd7efb6">{"x":{"question":"Which of the following is an ordinal variable?","answers":[{"option":"Customer saticefaction (saticefied,OK, disaticefied)","correct":true,"message":null},{"option":"Preference of the Democratic presidential candidate (Biden, Warren, Sanders)","correct":false,"message":null},{"option":"The country of origin.","correct":false,"message":null}],"label":"review_a1","skipStartButton":true,"perQuestionResponseAnswers":true,"perQuestionResponseMessaging":true,"preventUnanswered":true,"displayQuestionCount":false,"displayQuestionNumber":false,"disableRanking":true,"nextQuestionText":"","checkAnswerText":"Submit Answer","allowRetry":true,"randomSortAnswers":false,"json":{"info":{"name":"","main":""},"questions":[{"q":"Which of the following is an ordinal variable?","a":[{"option":"Customer saticefaction (saticefied,OK, disaticefied)","correct":true,"message":null},{"option":"Preference of the Democratic presidential candidate (Biden, Warren, Sanders)","correct":false,"message":null},{"option":"The country of origin.","correct":false,"message":null}],"correct":"Correct!","incorrect":"Incorrect."}]}},"evals":[],"jsHooks":[]}</script>
<hr />
</div>
</div>
<div id="section-multinomial-distribution" class="section level2">
<h2>Multinomial distribution</h2>
<ul>
<li>To understand categorical regression models, you need first to understand the multinomial distribution. Multinomial distribution is hard to grasp at first because it is a multivariate distribution.<br />
</li>
<li>The cannonical example that is used for multinomial distribution is the rolls of multiple die. A fair 6 sided dice has 6 category outcome with each side coming up with an equal probability. If you roll a dice it will come up on one of the faces.</li>
</ul>
<pre><code>## [1] 2</code></pre>
<p>if you were to use dummy coding, this would look like</p>
<pre><code>## [1] 0 1 0 0 0 0</code></pre>
<p>If you roll 10 die then there will be multiple die with same faces.</p>
<pre><code>##  [1] 1 5 1 5 5 2 5 3 5 3</code></pre>
<p>If you were to tally up the number of faces, then you will have counts associated with each face of a dice that would sum to 10.</p>
<pre><code>## rolls
## 1 2 3 5 
## 2 1 2 5</code></pre>
<p>This is an example of a multinomial distribution.</p>
<ul>
<li>Multinomial distribution is a multivariate random variable <span class="math inline">\(\mathbf{y}\)</span> with <span class="math inline">\(c\)</span> categories.</li>
<li>Let <span class="math inline">\(\pi_1, \pi_2,\dots, \pi_c\)</span> be the probabilities associated with each of the categories where <span class="math inline">\(\pi_1 + \pi_2+ \dots + \pi_c=1\)</span>.</li>
<li><p>If there is <span class="math inline">\(n\)</span> independent observations of <span class="math inline">\(\mathbf{y}\)</span> which result in <span class="math inline">\(y_1\)</span> outcomes in category 1, <span class="math inline">\(y_2\)</span> outcomes in category 2, and so on, each <span class="math inline">\(y_j\)</span> being the number of times <span class="math inline">\(j\)</span>th category occurred then, <span class="math display">\[\mathbf{y}=\left[\begin{array}{c}
y_1\\
y_2\\
\vdots\\
y_c
\end{array}\right]
\mbox{ with }
\sum^c y_j = n\]</span></p></li>
<li><span class="math inline">\(\mathbf{y}\)</span> is from multinomial distribution when it’s pdf is <span class="math display">\[f(\mathbf{y}|n,\boldsymbol{\pi})=\frac{n!}{y_1!y_2!\cdots y_c!}\pi_1^{y_1} \pi_2^{y_2}\cdots \pi_c^{y_c}\]</span> We denote using <span class="math inline">\(\mathbf{y}\sim Mult(n,\pi_1, \pi_2,\dots, \pi_c)\)</span></li>
<li>Expected value of the <span class="math inline">\(j\)</span>th category: <span class="math inline">\(E(y_j)=n\pi_j\)</span></li>
<li>Variance of the <span class="math inline">\(j\)</span>th category:<span class="math inline">\(Var(y_j)=n\pi_j(1-\pi_j)\)</span> and</li>
<li><p>Covariance between categories <span class="math inline">\(j\)</span> and <span class="math inline">\(k\)</span>: <span class="math inline">\(Cov(y_j,y_k)=-n\pi_j\pi_k\)</span></p></li>
</ul>
<hr />
<div id="section-multinomial-distribution-example" class="section level3">
<h3>Multinomial distribution (example)</h3>
<ul>
<li><p>The most elementary example of a phenomena that follow multinomial distribution is rolls of a dice. A 6 faced dice would have <span class="math inline">\(c=6\)</span> and if the dice is fair, chance of seeing each face is <span class="math inline">\(1/6\)</span>. Therefore, <span class="math inline">\(\boldsymbol{\pi} =(1/6,1/6,1/6,1/6,1/6,1/6)\)</span>.</p></li>
<li>A result of rolling a fair dice <span class="math display">\[\mathbf{y} \sim Mult(n=1,\boldsymbol{\pi} =(1/6,1/6,1/6,1/6,1/6,1/6))\]</span>
<ul>
<li>if you roll a dice, you can get only one face as an outcome.</li>
</ul></li>
</ul>
<p>For a <span class="math inline">\(i\)</span>th roll the outcome will be <span class="math inline">\(\mathbf{y}_i=(y_{i1},y_{i2},y_{i3},y_{i4},y_{i5},y_{i6})\)</span></p>
<table>
<thead>
<tr class="header">
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
<th align="center">Sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(y_{i1}\)</span></td>
<td align="center"><span class="math inline">\(y_{i2}\)</span></td>
<td align="center"><span class="math inline">\(y_{i3}\)</span></td>
<td align="center"><span class="math inline">\(y_{i4}\)</span></td>
<td align="center"><span class="math inline">\(y_{i5}\)</span></td>
<td align="center"><span class="math inline">\(y_{i6}\)</span></td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>only 1 of <span class="math inline">\(y_{ij}\)</span> is 1.</p>
<ul>
<li>If there are multiple observations this would be</li>
</ul>
<table>
<thead>
<tr class="header">
<th align="center">i</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
<th align="right">sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center"><span class="math inline">\(y_{11}\)</span></td>
<td align="center"><span class="math inline">\(y_{12}\)</span></td>
<td align="center"><span class="math inline">\(y_{13}\)</span></td>
<td align="center"><span class="math inline">\(y_{14}\)</span></td>
<td align="center"><span class="math inline">\(y_{15}\)</span></td>
<td align="center"><span class="math inline">\(y_{16}\)</span></td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center"><span class="math inline">\(y_{21}\)</span></td>
<td align="center"><span class="math inline">\(y_{22}\)</span></td>
<td align="center"><span class="math inline">\(y_{23}\)</span></td>
<td align="center"><span class="math inline">\(y_{24}\)</span></td>
<td align="center"><span class="math inline">\(y_{25}\)</span></td>
<td align="center"><span class="math inline">\(y_{26}\)</span></td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center"><span class="math inline">\(y_{31}\)</span></td>
<td align="center"><span class="math inline">\(y_{32}\)</span></td>
<td align="center"><span class="math inline">\(y_{33}\)</span></td>
<td align="center"><span class="math inline">\(y_{34}\)</span></td>
<td align="center"><span class="math inline">\(y_{35}\)</span></td>
<td align="center"><span class="math inline">\(y_{36}\)</span></td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="center">G</td>
<td align="center"><span class="math inline">\(y_{G1}\)</span></td>
<td align="center"><span class="math inline">\(y_{G2}\)</span></td>
<td align="center"><span class="math inline">\(y_{G3}\)</span></td>
<td align="center"><span class="math inline">\(y_{G4}\)</span></td>
<td align="center"><span class="math inline">\(y_{G5}\)</span></td>
<td align="center"><span class="math inline">\(y_{G6}\)</span></td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<ul>
<li>Count of each face when rolling 10 fair die <span class="math display">\[\mathbf{y} \sim Mult(n=10,\boldsymbol{\pi} =(1/6,1/6,1/6,1/6,1/6,1/6))\]</span>
<ul>
<li>if you roll a dice 10 times, you can get only one face for each trial but you can get 10 of them. Therefore, <span class="math inline">\(\mathbf{y}\)</span> will have 10 trials divided into 6 categories.</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="center">i</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
<th align="right">sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center"><span class="math inline">\(y_{11}\)</span></td>
<td align="center"><span class="math inline">\(y_{12}\)</span></td>
<td align="center"><span class="math inline">\(y_{13}\)</span></td>
<td align="center"><span class="math inline">\(y_{14}\)</span></td>
<td align="center"><span class="math inline">\(y_{15}\)</span></td>
<td align="center"><span class="math inline">\(y_{16}\)</span></td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center"><span class="math inline">\(y_{21}\)</span></td>
<td align="center"><span class="math inline">\(y_{22}\)</span></td>
<td align="center"><span class="math inline">\(y_{23}\)</span></td>
<td align="center"><span class="math inline">\(y_{24}\)</span></td>
<td align="center"><span class="math inline">\(y_{25}\)</span></td>
<td align="center"><span class="math inline">\(y_{26}\)</span></td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center"><span class="math inline">\(y_{31}\)</span></td>
<td align="center"><span class="math inline">\(y_{32}\)</span></td>
<td align="center"><span class="math inline">\(y_{33}\)</span></td>
<td align="center"><span class="math inline">\(y_{34}\)</span></td>
<td align="center"><span class="math inline">\(y_{35}\)</span></td>
<td align="center"><span class="math inline">\(y_{36}\)</span></td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="center">G</td>
<td align="center"><span class="math inline">\(y_{G1}\)</span></td>
<td align="center"><span class="math inline">\(y_{G2}\)</span></td>
<td align="center"><span class="math inline">\(y_{G3}\)</span></td>
<td align="center"><span class="math inline">\(y_{G4}\)</span></td>
<td align="center"><span class="math inline">\(y_{G5}\)</span></td>
<td align="center"><span class="math inline">\(y_{G6}\)</span></td>
<td align="right">10</td>
</tr>
</tbody>
</table>
<hr />
</div>
<div id="section-binomial-is-a-special-case-of-multinomial" class="section level3">
<h3>Binomial is a special case of multinomial</h3>
<ul>
<li>When there are 2 classes (<span class="math inline">\(c = 2\)</span>), so
<ul>
<li>out of <span class="math inline">\(n\)</span> trials if <span class="math inline">\(y_1\)</span> is number of occurrence of the first class, then <span class="math inline">\(y_2=n-y_1\)</span> is automatically the occurrence of the second class</li>
<li>Since the occurrence of two probabilities sum to 1 <span class="math display">\[\pi_2 = 1-\pi_1\]</span></li>
</ul></li>
<li>If we plug these into the multinomial formula we have <span class="math display">\[\begin{align}
f(\mathbf{y}|n)&amp;=\frac{n!}{y_1!y_2!}\pi_1^{y_1}\pi_2^{y_2}\\
&amp;=\frac{n!}{y_1!(n-y_1)!}\pi_1^{y_1}( 1-\pi_1)^{n-y_1}\\
&amp;= \binom{n}{y_1}\pi_1^{y_1}( 1-\pi_1)^{n-y_1}
\end{align}\]</span> which is a density for binomial distribution.</li>
</ul>
<!-- - It also happens that $y_1+y_2\sim Bin(n,\pi_1+\pi_2)$ -->
<hr />
</div>
<div id="section-marginal-distribution" class="section level3">
<h3>Marginal Distribution</h3>
<ul>
<li>Someone comes to you and says I’ll roll <span class="math inline">\(n\)</span> dies, if 1 or 6 comes out you win and otherwise he wins. How can you formulate a probability model that would describe such game?</li>
<li><p>If you think carefully, you will notice that the probability of coming up on a face that is not 1 nor 6 is just the sum of probabilities that comes up 2,3,4,and 5. If you treat the 4 faces as if they are one face, you have a dice with 3 faces.</p></li>
<li><p>In <span class="math inline">\(n\)</span> dice rolls, if all we cared was the probability of 1, 6 and other. That would again follow a multinomial distribution <span class="math display">\[y_1,y_6,y_o\sim Mult(n,\pi_1,\pi_6, 1-\pi_1-\pi_6)\]</span></p></li>
</ul>
</div>
<div id="section-conditional-distribution" class="section level3">
<h3>Conditional distribution</h3>
<ul>
<li><p>Someone rolls <span class="math inline">\(n\)</span> dies having certain probability for each face. You find out that there was certain number of 1s (<span class="math inline">\(a\)</span>), what’s the probability distribution of the other faces? So to say it another way, if you rolled <span class="math inline">\(n\)</span> dice but you ignored all the outcomes that was 1, what probability distribution is that? It’s the probability distribution of a dice with out face 1 rolled <span class="math inline">\(n-a\)</span> times!</p></li>
<li><p>In <span class="math inline">\(n\)</span> dice rolls, if we wanted a conditional distribution of faces 2 to 6 given <span class="math inline">\(y_1=a\)</span> that again is multinomial <span class="math display">\[(y_2,y_3,y_4,y_5,y_6)\sim Mult(n-a,\pi_2/(1-\pi_1), \cdots, \pi_6/(1-\pi_1))\]</span></p></li>
</ul>
<hr />
</div>
<div id="section-poisson-conditioned-on-the-sum-is-multinomial" class="section level3">
<h3>Poisson conditioned on the sum is multinomial</h3>
<ul>
<li>It turns out that there is a relationship between Poisson distribution and multinomial distribution, which becomes important later on. If <span class="math inline">\(c\)</span> event happen independently following Poisson distribution each having a certain rate, if we know that <span class="math inline">\(n\)</span> outcome occurred then that distribution is Multinomial.</li>
<li><p>For example, if we had <span class="math inline">\(5\)</span> hospitals that had people visiting emergency rooms between some time intervals. If we knew that 15 people visited the emergency rooms during that time, then the number of people visiting each of the hospitals will follow a multinomial distribution.</p></li>
<li>Let <span class="math inline">\(y_1,\dots,y_c\)</span> be independent Poisson random variable. <span class="math display">\[y_j \sim Poisson(\theta_j)\]</span></li>
<li>Their joint density <span class="math display">\[f(\mathbf{y})=\prod_{j=1}^{c}\frac{\theta_j^{y_j} \exp(-\theta_j)}{y_j!}\]</span></li>
<li>If we let <span class="math inline">\(n=y_1+y_2+\dots+y_c\)</span> then <span class="math display">\[n\sim Poisson(\theta_1+\theta_2+\cdots+\theta_c)\]</span></li>
<li><p>Distribution of <span class="math inline">\(\mathbf{y}\)</span> conditional on <span class="math inline">\(n\)</span> is <span class="math display">\[\begin{align}
f(\mathbf{y}|n)&amp;=\prod_{j=1}^{c}\frac{\theta_j^{y_j} \exp(-\theta_j)}{y_j!}/\frac{(\theta_1+\theta_2+\cdots+\theta_c)^n \exp(-(\theta_1+\theta_2+\cdots+\theta_c))}{n!}\\
&amp;=\left(\frac{\theta_1}{\sum^c\theta_k}\right)^{y_1}\left(\frac{\theta_2}{\sum^c\theta_k}\right)^{y_2}\cdots \left(\frac{\theta_c}{\sum^c\theta_k}\right)^{y_c}\frac{n!}{y_1!y_2!\cdots y_c!}\\
&amp;=\pi_1^{y_1}\pi_2^{y_2}\cdots \pi_c^{y_c}\frac{n!}{y_1!y_2!\cdots y_c!}
\end{align}\]</span></p></li>
</ul>
<hr />
</div>
<div id="section-multinomial-distribution-r" class="section level3">
<h3>Multinomial distribution (R)</h3>
<ul>
<li>You can generate a sample from multinomial distribution using <code>rmultinom</code></li>
</ul>
<pre class="r"><code>(y=rmultinom(1,size=1,prob=c(0.1,0.3,0.2,0.4)))</code></pre>
<pre><code>##      [,1]
## [1,]    0
## [2,]    0
## [3,]    0
## [4,]    1</code></pre>
<ul>
<li>Multiple samples can be generated by specifying n</li>
</ul>
<pre class="r"><code>(y=rmultinom(5,size=1,prob=c(0.1,0.3,0.2,0.4)))</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4] [,5]
## [1,]    0    0    0    0    0
## [2,]    0    0    0    0    0
## [3,]    0    0    0    0    0
## [4,]    1    1    1    1    1</code></pre>
<hr />
</div>
<div id="section-multinomial-distribution-random-number-generation" class="section level3">
<h3>Multinomial distribution (random number generation)</h3>
<ul>
<li>How would you generate a random number from a multinomial distribution?</li>
<li>If we can generate random number between 0 and 1.
<ol style="list-style-type: decimal">
<li>Split <span class="math inline">\((0,1)\)</span> into <span class="math inline">\(c\)</span> intervals proportional to <span class="math inline">\(\pi_1, \pi_2,\dots, \pi_c\)</span></li>
<li>Generate <span class="math inline">\(n\)</span> random numbers from <span class="math inline">\(Uniform(0,1)\)</span></li>
<li>Count the number of times the a generated numbers fell in the intervals.</li>
</ol></li>
</ul>
<pre class="r"><code>p&lt;-c(0.1,0.3,0.2,0.4)
z&lt;-runif(100,0,1)</code></pre>
<p><img src="09_GLM_Multinomial_files/figure-html/unnamed-chunk-8-1.png" width="80%" style="display: block; margin: auto;" /></p>
<pre><code>## samp
##   (0,0.1] (0.1,0.4] (0.4,0.6]   (0.6,1] 
##         9        39        12        40</code></pre>
</div>
</div>
<div id="section-nominal-categorical-outcome" class="section level2">
<h2>Nominal Categorical Outcome</h2>
<ul>
<li>Nominal categorical outcome is a categorical outcome that does not have ordering. When there is no ordering between the outcome, the reference point becomes important because the effects we speak of is usually relative. Let’s start by looking at an example.</li>
</ul>
<div id="section-choice-for-mode-of-travel" class="section level3">
<h3>Choice for mode of travel</h3>
<ul>
<li>Data on travel mode choice for travel between Sydney and Melbourne, Australia.</li>
<li>Dataset is a binary matrix with 210 individuals times 4 modes of travel</li>
</ul>
<pre><code>##        
##          no yes
##   air   152  58
##   train 147  63
##   bus   180  30
##   car   151  59</code></pre>
<ul>
<li><p>The type of travel mode does not have a clear order. One can order them by the price of their tickets, but they don’t live on a single spectrum.</p></li>
<li><p>Empirical proportion would be:</p></li>
</ul>
<pre><code>##       air     train       bus       car 
## 0.3815789 0.4285714 0.1666667 0.3907285</code></pre>
<ul>
<li><p>If this was a representative sample of some population of interest, this information would mean something. Nevertheless, when we say that 38% of the people chose air as their means of travel, that information itself does not have practical value unless there is some other information that one can reference to. For example, if we say that people prefer air travel 3 times more than bus travel and preference comparing air and car is about the same, then that starts to tell a story.</p></li>
<li><p>To rephrase this, the comparisons are meaningful only with respect to some baseline category. And that’s exactly how we will model a nominal categorical outcome.</p></li>
</ul>
</div>
<div id="section-multinomial-logit-model" class="section level3">
<h3>Multinomial logit model</h3>
<ul>
<li>Let number of response category be <span class="math inline">\(c\)</span>.</li>
<li><span class="math inline">\(\pi_{ij}\)</span> be probability of response in category <span class="math inline">\(j\)</span> for subject <span class="math inline">\(i\)</span>, <span class="math inline">\(\sum_j\pi_{ij}=1\)</span>.</li>
<li><span class="math inline">\(\mathbf{y}_i=(y_{i1},\cdots,y_{ic})\)</span> for <span class="math inline">\(i=1,\dots,N\)</span></li>
<li><span class="math inline">\(y_{ij}=1\)</span> when there is response in category <span class="math inline">\(j\)</span> and 0 otherwise.</li>
<li><span class="math inline">\(\sum_j y_{ij}=1\)</span> hence the multinomial probability distribution for subject <span class="math inline">\(i\)</span> is <span class="math display">\[P(y_{i1},\cdots,y_{ic})=\pi_{i1}^{y_{i1}}\cdots \pi_{ic}^{y_{ic}}\]</span></li>
</ul>
<hr />
<ul>
<li><p>We pair each response category with the baseline category <code>c</code> <span class="math display">\[\log\frac{\pi_{i1}}{\pi_{ic}},\log\frac{\pi_{i2}}{\pi_{ic}},\cdots, \log\frac{\pi_{i(c-1)}}{\pi_{ic}}\]</span></p></li>
<li><p>The jth baseline category logit, <span class="math inline">\(\log\frac{\pi_{ij}}{\pi_{ic}}\)</span> is the logit of a conditional probability <span class="math display">\[\begin{align}
&amp;logit[P(y_{ij}=1|y_{ij}= 1\mbox{ or }y_{ic}=1)]\\
&amp;=\log\left[\frac{P(y_{ij}=1|y_{ij}= 1\mbox{ or }y_{ic}=1)}{1-P(y_{ij}=1|y_{ij}= 1\mbox{ or } y_{ic}=1)}\right]=\log\frac{\pi_{ij}}{\pi_{ic}}
\end{align}\]</span></p></li>
<li>Multinomial logit model (Baseline-category logit): <span class="math display">\[\log\frac{\pi_{ij}}{\pi_{ic}}=\mathbf{X}_i\boldsymbol{\beta}_j=\sum^p_{k=1}\beta_{jk}x_{ik}, j=1,\dots, (c-1)\]</span></li>
<li><p>These <span class="math inline">\((c-1)\)</span> equations determine equations for logits with other pairs of response categories <span class="math display">\[\log\frac{\pi_{ia}}{\pi_{ib}}=\log\frac{\pi_{ia}}{\pi_{ic}}-\log\frac{\pi_{ib}}{\pi_{ic}}=\mathbf{X}_i(\boldsymbol{\beta}_a-\boldsymbol{\beta}_b)\]</span></p></li>
</ul>
<hr />
<ul>
<li><p>We can express response probability as <span class="math display">\[\pi_{ij}=\pi_{ic}exp(\mathbf{X}_i\boldsymbol{\beta}_j)\]</span></p></li>
<li>Since <span class="math inline">\(\sum^c_{j=1} \pi_{ij} =1\)</span> <span class="math display">\[\pi_{ic}=\frac{1}{1+\sum^{c-1}_{h=1}exp(\mathbf{X}_i\boldsymbol{\beta}_h)}\]</span></li>
<li><p>Therefore <span class="math display">\[\begin{align}
\hat{\pi}_{ic}=
\frac{
exp( \mathbf{X}_i \boldsymbol{\beta}_j)}
{ 1 + \sum^{c-1}_{h=1} 
exp(\mathbf{X}_i \boldsymbol{\beta}_h)
}
\end{align}\]</span></p></li>
</ul>
<p>with <span class="math inline">\(\beta_c=0\)</span></p>
<hr />
</div>
<div id="section-interpretation" class="section level3">
<h3>Interpretation</h3>
<ul>
<li>Interpretation of effects overall is NOT simple</li>
<li>If we take derivative wrt <span class="math inline">\(x_{ik}\)</span> <span class="math display">\[\frac{\partial\pi_{ij}}{\partial x_{ik}}=\pi_{ij}(\beta_{jk}-\sum_{j&#39;}\pi_{ij&#39;}\beta_{j&#39;k})\]</span></li>
<li>Unlike logistic regression this rate of change does not always have the same sign as <span class="math inline">\(\beta_{jk}\)</span>.</li>
</ul>
<hr />
</div>
<div id="section-fitting-the-model" class="section level3">
<h3>fitting the model</h3>
<ul>
<li>Contribution to the log-likelihood from subject i is <span class="math display">\[\begin{align}
\log(\prod^c_{j=1}\pi_{ij}^{y_{ij}})&amp;=
\sum y_{ij}\log\pi_{ij}+(1-\sum y_{ij})\log\pi_{ic}\\
&amp;= \sum y_{ij}\log\frac{\pi_{ij}}{\pi_{ic}}+\log\pi_{ic}
\end{align}\]</span></li>
<li>This is natural parameters for the multinomial distribution.</li>
<li><p>baseline category logit is a the canonical link functions for mulitinomial GLMs.</p></li>
<li><p>For <span class="math inline">\(\log\frac{\pi_{ij}}{\pi_{ic}}\)</span> we substitute <span class="math inline">\(\mathbf{X}_i\boldsymbol{\beta}_j\)</span></p></li>
<li><p>And <span class="math display">\[\begin{align}
\hat{\pi}_{ic}=\frac{1}{1+\sum^{c-1}_{h=1} \exp(\mathbf{X}_i\boldsymbol{\beta}_h)}
\end{align}\]</span></p></li>
<li><p>Resulting in the log-likelihood function <span class="math display">\[\begin{align}
L(\boldsymbol{\beta};y)=...
\end{align}\]</span></p></li>
</ul>
<hr />
</div>
<div id="section-fitting-the-model-1" class="section level3">
<h3>fitting the model</h3>
<ul>
<li>Taking derivative wrt <span class="math inline">\(\beta_{jk}\)</span> <span class="math display">\[\begin{align}
\frac{\partial L(\boldsymbol{\beta};y)}{\partial \beta_{jk}}=
\sum_{i=1}^N x_{ik}(y_{ij}-\pi_{ij})
\end{align}\]</span></li>
<li>The likelihood equations are <span class="math display">\[\begin{align}
\sum_{i=1}^N x_{ik}y_{ij}=\sum_{i=1}^N x_{ik}\pi_{ij}
\end{align}\]</span></li>
<li>Information matrix is <span class="math display">\[\begin{align}
-\frac{\partial^2 L(\boldsymbol{\beta};y)}{\partial \boldsymbol{\beta}_{j}\partial \boldsymbol{\beta}_{j&#39;}^{T}}=\sum_{i=1}^N \pi_{ij}[1(j=j&#39;)-\pi_{ij}]\mathbf{x}_i^{T}\mathbf{x}_i
\end{align}\]</span></li>
<li>Newton-Raphson or Fisher scoring are identical and convergence is fast.</li>
</ul>
<hr />
</div>
<div id="section-multionomial-logit-in-r" class="section level3">
<h3>Multionomial Logit in R</h3>
<ul>
<li><p>There are at least five packages in R that you can fit multinomial logit model with. Each model differs in how one specifies the formula but overall result should be the same. It’s good to know different options so that you can compare the results.</p></li>
<li><p><code>multinom</code> function in <code>nnet</code> package is a classic option that uses Maximum conditional likelihood. It is a neural network model with no hidden layer and softmax output.</p></li>
</ul>
<pre class="r"><code>library(nnet)
multinom(formula=...,weights=...,data=...)</code></pre>
<ul>
<li><code>mlogit</code> function in <code>mlogit</code> package is another classical method that use full information maximum likelihood. The details can be found <a href="https://cran.r-project.org/web/packages/mlogit/vignettes/mlogit.pdf">here</a></li>
</ul>
<pre class="r"><code>library(mlogit)
mldf &lt;- mlogit.data(data=..., choice=...)
mlogit.mod &lt;- mlogit::mlogit( formula, data=mldf)</code></pre>
<ul>
<li><code>mnlogit</code> function in <code>mnlogit</code> package claims they are much faster version of <code>mlogit</code>. You an read about them <a href="https://cran.r-project.org/web/packages/mnlogit/vignettes/mnlogit.pdf">here</a>.</li>
</ul>
<pre class="r"><code>library(mnlogit)
mnlogit(formula, data)</code></pre>
<ul>
<li><code>globaltest</code> package offers yet another <code>mlogit</code> function. I don’t know the benefit of this version of <code>mlogit</code> over the <code>mlogit::mlogit</code> but it’s clear you don’t what to load both libraries at once.</li>
</ul>
<pre class="r"><code># Install
source(&quot;https://bioconductor.org/biocLite.R&quot;)
biocLite(&quot;globaltest&quot;)
library(globaltest)
globaltest::mlogit(formula=..., data=...)</code></pre>
<ul>
<li>Alternatively, <code>vglm</code> package by in <code>VGAM</code> package is becoming increasingly popular.</li>
</ul>
<pre class="r"><code>library(VGAM)
vglm(formula=...,family=multinomial, data=...)</code></pre>
<ul>
<li>Data formatting is slightly confusing but important to understand. There are three ways to fit the same model depending on how you structure your data. We will look at a fake data since it will simplify the understanding. For example, if your data looked like the following</li>
</ul>
<pre class="r"><code>x1&lt;-sample(1:3,10,replace=TRUE)
x2&lt;-sample(1:2,10,replace=TRUE)
y&lt;- factor(sample(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;),10,replace = TRUE))
datsample&lt;-data.frame(y,x1,x2)
datsample</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["y"],"name":[1],"type":["fctr"],"align":["left"]},{"label":["x1"],"name":[2],"type":["int"],"align":["right"]},{"label":["x2"],"name":[3],"type":["int"],"align":["right"]}],"data":[{"1":"C","2":"2","3":"1"},{"1":"B","2":"1","3":"2"},{"1":"B","2":"3","3":"1"},{"1":"A","2":"3","3":"1"},{"1":"C","2":"3","3":"1"},{"1":"A","2":"3","3":"1"},{"1":"C","2":"1","3":"2"},{"1":"C","2":"2","3":"1"},{"1":"A","2":"1","3":"1"},{"1":"B","2":"2","3":"2"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<div id="section-long-format" class="section level4">
<h4>long format</h4>
<p>This is probably the finest that you can specify your data. When your predictors have continuous variable, you will need to use this format.</p>
<pre class="r"><code>fit&lt;-multinom(y~x1+x2,data=datsample,trace=FALSE)
summary(fit)</code></pre>
<pre><code>## Call:
## multinom(formula = y ~ x1 + x2, data = datsample, trace = FALSE)
## 
## Coefficients:
##   (Intercept)           x1        x2
## B  -43.171517  6.851519877 22.211054
## C   -8.097129 -0.000884919  8.099412
## 
## Std. Errors:
##   (Intercept)        x1       x2
## B    132.3890 23.876427 74.63952
## C     57.5855  1.095375 57.44647
## 
## Residual Deviance: 15.59316 
## AIC: 27.59316</code></pre>
</div>
<div id="section-row-counts-format" class="section level4">
<h4>row counts format</h4>
<p>If your predictors are all discrete, you can summarize them into count format.</p>
<pre class="r"><code>datsum&lt;-datsample%&gt;%group_by(x1,x2,y)%&gt;%summarise(count_y=length(y)) %&gt;%
  complete(x1,x2,y, fill = list(count_y = 0))
datsum</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["x1"],"name":[1],"type":["int"],"align":["right"]},{"label":["x2"],"name":[2],"type":["int"],"align":["right"]},{"label":["y"],"name":[3],"type":["fctr"],"align":["left"]},{"label":["count_y"],"name":[4],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"1","3":"A","4":"1"},{"1":"1","2":"1","3":"B","4":"0"},{"1":"1","2":"1","3":"C","4":"0"},{"1":"1","2":"2","3":"A","4":"0"},{"1":"1","2":"2","3":"B","4":"1"},{"1":"1","2":"2","3":"C","4":"1"},{"1":"2","2":"1","3":"A","4":"0"},{"1":"2","2":"1","3":"B","4":"0"},{"1":"2","2":"1","3":"C","4":"2"},{"1":"2","2":"2","3":"A","4":"0"},{"1":"2","2":"2","3":"B","4":"1"},{"1":"2","2":"2","3":"C","4":"0"},{"1":"3","2":"1","3":"A","4":"2"},{"1":"3","2":"1","3":"B","4":"1"},{"1":"3","2":"1","3":"C","4":"1"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>multinom(y~x1+x2,weight=count_y,data=datsum)</code></pre>
<pre><code>## # weights:  12 (6 variable)
## initial  value 10.986123 
## iter  10 value 8.578892
## iter  20 value 7.879871
## iter  30 value 7.841438
## iter  40 value 7.811197
## iter  50 value 7.801740
## iter  60 value 7.800815
## iter  70 value 7.797601
## iter  80 value 7.797314
## iter  90 value 7.797084
## iter 100 value 7.796582
## final  value 7.796582 
## stopped after 100 iterations</code></pre>
<pre><code>## Call:
## multinom(formula = y ~ x1 + x2, data = datsum, weights = count_y)
## 
## Coefficients:
##   (Intercept)           x1        x2
## B  -43.171517  6.851519877 22.211054
## C   -8.097129 -0.000884919  8.099412
## 
## Residual Deviance: 15.59316 
## AIC: 27.59316</code></pre>
</div>
<div id="section-tabulated-format" class="section level4">
<h4>Tabulated format</h4>
<p>In many cases, the counts are further compressed into a table format. In this kind of situation, you will specify the columns of the outcome on the left hand side and the combination of the attributes on the right hand side.</p>
<pre class="r"><code>dattab&lt;-dcast(datsample, x1+x2~y)
dattab</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["x1"],"name":[1],"type":["int"],"align":["right"]},{"label":["x2"],"name":[2],"type":["int"],"align":["right"]},{"label":["A"],"name":[3],"type":["int"],"align":["right"]},{"label":["B"],"name":[4],"type":["int"],"align":["right"]},{"label":["C"],"name":[5],"type":["int"],"align":["right"]}],"data":[{"1":"1","2":"1","3":"1","4":"0","5":"0"},{"1":"1","2":"2","3":"0","4":"1","5":"1"},{"1":"2","2":"1","3":"0","4":"0","5":"2"},{"1":"2","2":"2","3":"0","4":"1","5":"0"},{"1":"3","2":"1","3":"2","4":"1","5":"1"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>fittab&lt;-multinom(as.matrix(dattab[,3:5])~x1+x2,data=dattab,trace=FALSE)</code></pre>
<!-- ## [Example] Mode of travel -->
<!-- - Lets look at the data on travel mode choice for travel between Sydney and Melbourne, Australia from [@greene2003econometric]. -->
<!-- - Each row is a cobination of individual and a travel mode -->
<!-- - The variables we will look at are -->
<!--   - `mode`:  Factor indicating travel mode with levels "car", "air", "train", or "bus". -->
<!--   - `choice`: Factor indicating choice with levels "no" and "yes". -->
<!--   - `wait`: Terminal waiting time, 0 for car. -->
<!--   - `travel`: Travel time in the vehicle. -->
<!--   - `gcost`: Generalized cost measure. -->
<!--   - `income`: Household income. -->
<!-- Here are EDA for travel time vs wait time -->
<!-- ```{r,fig.width=12,fig.height=3} -->
<!-- ggplot(TravelMode)+geom_jitter()+ -->
<!--   aes(x=wait, y=travel,color=factor(choice))+ -->
<!--   facet_grid(~mode) -->
<!-- ``` -->
<!-- and cost vs income. -->
<!-- ```{r,fig.width=12,fig.height=3} -->
<!-- ggplot(TravelMode)+geom_jitter()+ -->
<!--   aes(x=income, y=gcost,color=factor(choice))+ -->
<!--   facet_grid(~mode) -->
<!-- ``` -->
<!-- - If you look carefully, you might notice there's a weird strip of vertical red dots on the wait vs travel time plot.  Faceting the data by choice reveals that the waiting time for those travel choices that people did not choose is identical, suggesting those values were filled in mechanistically.  This is a text book example but it tells you how important it is to plot the data. -->
<!-- ```{r,fig.width=12,fig.height=6} -->
<!-- ggplot(TravelMode)+geom_jitter()+ -->
<!--   aes(x=wait, y=travel,color=factor(choice))+ -->
<!--   facet_grid(choice~mode) -->
<!-- ``` -->
<!-- What this figure tells you is that the waiting time variable reflexts more of a person's belief rather than the actual time.  Interpretation should take that into account and be cautious. -->
<!-- ### Fitting the model -->
<!-- ```{r} -->
<!-- vgTrvMd<-vglm(choice ~ gcost + wait + income,family=multinomial, data=TravelMode) -->
<!-- summary(vgTrvMd) -->
<!-- ``` -->
<!-- ---- -->
<hr />
</div>
</div>
<div id="section-inference" class="section level3">
<h3>Inference</h3>
<ul>
<li>With large <span class="math inline">\(n\)</span>, based on the asymptotic <span class="math display">\[\boldsymbol{\hat{\beta}} \sim N(\beta,\boldsymbol{\mathcal{I}}^{-1})\]</span>
<ul>
<li>The <span class="math inline">\(\boldsymbol{\hat{\beta}}_j\)</span>s are correlated.</li>
</ul></li>
<li>Likelihood ratio, Wald, and score test can be used.</li>
<li>Global model check can be done through
<ul>
<li>Deviance <span class="math display">\[D=2\sum^N_{i=1}\sum^c_{j=1}n_iy_{ij}\log\frac{n_iy_{ij}}{n_i\hat{\pi}_{ij}}=2\sum \mbox{observed}\log\frac{\mbox{observed}}{\mbox{fitted}}\]</span></li>
<li>Pearson statistics <span class="math display">\[X^2=2\sum^N_{i=1}\sum^c_{j=1}\frac{(n_iy_{ij}-n_i\hat{\pi}_{ij})^2}{n_i\hat{\pi}_{ij}}=
\sum \frac{(\mbox{observed}-\mbox{fitted})^2}{\mbox{fitted}}\]</span></li>
<li>They are approximately <span class="math inline">\(\chi^2\)</span> when all cell frequency are bigger than 5.</li>
<li>degrees of freedom is <span class="math inline">\(N(c-1)-p\)</span></li>
</ul></li>
</ul>
<hr />
</div>
</div>
<div id="section-example-alligator-food-preference" class="section level2">
<h2>[Example] Alligator food preference</h2>
<ul>
<li>What does Alligators like to eat? Researchers went out and studied what the alligators are feeding on at different locations for adult and non-adult alligators. This example comes from <span class="citation">[@agresti2015foundations]</span>.</li>
</ul>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["lake"],"name":[1],"type":["fctr"],"align":["left"]},{"label":["size"],"name":[2],"type":["fctr"],"align":["left"]},{"label":["Fish"],"name":[3],"type":["int"],"align":["right"]},{"label":["Invertebrate"],"name":[4],"type":["int"],"align":["right"]},{"label":["Reptile"],"name":[5],"type":["int"],"align":["right"]},{"label":["Bird"],"name":[6],"type":["int"],"align":["right"]},{"label":["Other"],"name":[7],"type":["int"],"align":["right"]}],"data":[{"1":"Hancock","2":"nonadult","3":"23","4":"4","5":"2","6":"2","7":"8"},{"1":"Hancock","2":"adult","3":"7","4":"0","5":"1","6":"3","7":"5"},{"1":"Ocklawaha","2":"nonadult","3":"5","4":"11","5":"1","6":"0","7":"3"},{"1":"Ocklawaha","2":"adult","3":"13","4":"8","5":"6","6":"1","7":"0"},{"1":"Trafford","2":"nonadult","3":"5","4":"11","5":"2","6":"1","7":"5"},{"1":"Trafford","2":"adult","3":"8","4":"7","5":"6","6":"3","7":"5"},{"1":"George","2":"nonadult","3":"16","4":"19","5":"1","6":"2","7":"3"},{"1":"George","2":"adult","3":"17","4":"1","5":"0","6":"1","7":"3"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<ul>
<li><p>Initial inspection of the data reveals that</p>
<ul>
<li>adults and non-adults prefer to eat different things even at the same lake.</li>
<li>what the creatures eat is dependent on the location.</li>
</ul></li>
</ul>
<p><img src="09_GLM_Multinomial_files/figure-html/unnamed-chunk-21-1.png" width="90%" style="display: block; margin: auto;" /></p>
<hr />
<div id="section-fitted-model" class="section level3">
<h3>Fitted model</h3>
<ul>
<li>The outcomes are vectors of number of animals being eaten. These are specified as a matrix similar to the way the binomial model was formulated. The last category is taken as the baseline, which in the below example is the <code>Fish</code>.</li>
</ul>
<pre class="r"><code>gator_fit&lt;-vglm(cbind(Invertebrate, Reptile, Bird, Other,Fish)
                   ~ size+lake,
                family=multinomial,data=gator)</code></pre>
<!-- ggg<-gator[,list( lake,size,Invertebrate=Invertebrate/Fish, Reptile=Reptile/Fish, Bird=Bird/Fish, Othe=Other/Fish)] -->
<!-- ggplot(melt(ggg,id.vars=c("lake","size")))+ -->
<!-- geom_point()+aes(x=lake,y=value,color=size)+facet_wrap(~variable) -->
<hr />
<p>The estimated coefficients are as follows.</p>
<pre><code>##                 Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept):1      -3.21       0.64   -5.02     0.00
## (Intercept):2      -2.07       0.71   -2.93     0.00
## (Intercept):3      -1.40       0.61   -2.30     0.02
## (Intercept):4      -1.08       0.47   -2.29     0.02
## sizenonadult:1      1.46       0.40    3.68     0.00
## sizenonadult:2     -0.35       0.58   -0.61     0.54
## sizenonadult:3     -0.63       0.64   -0.98     0.33
## sizenonadult:4      0.33       0.45    0.74     0.46
## lakeOcklawaha:1     2.60       0.66    3.93     0.00
## lakeOcklawaha:2     1.22       0.79    1.55     0.12
## lakeOcklawaha:3    -1.35       1.16   -1.16     0.25
## lakeOcklawaha:4    -0.82       0.73   -1.12     0.26
## lakeTrafford:1      2.78       0.67    4.14     0.00
## lakeTrafford:2      1.69       0.78    2.17     0.03
## lakeTrafford:3      0.39       0.78    0.50     0.62
## lakeTrafford:4      0.69       0.56    1.23     0.22
## lakeGeorge:1        1.66       0.61    2.71     0.01
## lakeGeorge:2       -1.24       1.19   -1.05     0.29
## lakeGeorge:3       -0.70       0.78   -0.89     0.37
## lakeGeorge:4       -0.83       0.56   -1.48     0.14</code></pre>
<ul>
<li>We have as a result 4 prediction equations.
<ul>
<li>log odds of selecting invertebrate over fish <span class="math display">\[logit\left(\frac{\hat{\pi}_{i1}}{\hat{\pi}_{i5}}\right)=-3.21+1.46 x_i^{sizeNoAdlt}+2.6x_i^{lakeOck}+2.78x_i^{lakeTrf}+1.66x_i^{lakeGrg}\]</span></li>
<li><p>log odds of selecting reptile over fish <span class="math display">\[logit\left(\frac{\hat{\pi}_{i2}}{\hat{\pi}_{i5}}\right)=-2.07+-0.35 x_i^{sizeNoAdlt}+1.22x_i^{lakeOck}+1.69x_i^{lakeTrf}+-1.24x_i^{lakeGrg}\]</span></p></li>
<li>log odds of selecting bird over fish <span class="math display">\[logit\left(\frac{\pi_{i3}}{\pi_{i5}}\right)=-1.4+-0.63 x_i^{sizeNoAdlt}+-1.35x_i^{lakeOck}+0.39x_i^{lakeTrf}+-0.7x_i^{lakeGrg}\]</span></li>
<li><p>log odds of selecting other over fish <span class="math display">\[logit\left(\frac{\hat{\pi}_{i4}}{\hat{\pi}_{i5}}\right)=-1.08+0.33 x_i^{sizeNoAdlt}+-0.82x_i^{lakeOck}+0.69x_i^{lakeTrf}+-0.83x_i^{lakeGrg}\]</span></p></li>
</ul></li>
<li>We can use the same method we used in logistic regression to interpret these coefficients.</li>
</ul>
<hr />
</div>
<div id="section-selecting-the-model" class="section level3">
<h3>Selecting the model</h3>
<p>Is there evidence to suggest there is difference in what the alligators eat at the different location and are there differences in the type of foods preferred by adults and non-adults? We fit three models and compared their AIC, which does seem to support our initial EDA result.</p>
<table>
<thead>
<tr class="header">
<th align="left">Model</th>
<th align="right">Deviance</th>
<th align="right">Df</th>
<th align="right">AIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">size+lake</td>
<td align="right">17.08</td>
<td align="right">12</td>
<td align="right">135.03</td>
</tr>
<tr class="even">
<td align="left">lake</td>
<td align="right">38.17</td>
<td align="right">16</td>
<td align="right">148.12</td>
</tr>
<tr class="odd">
<td align="left">size</td>
<td align="right">66.21</td>
<td align="right">24</td>
<td align="right">160.16</td>
</tr>
</tbody>
</table>
<hr />
<ul>
<li>We can get the fitted probability by using the <code>fitted</code> function. Looking at the fitted probabilities is a another way to understand the model fit.</li>
</ul>
<pre class="r"><code>tabl&lt;-cbind(gator[,1:2,with=FALSE],round(fitted(gator_fit),2))
kable(tabl)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">lake</th>
<th align="left">size</th>
<th align="right">Invertebrate</th>
<th align="right">Reptile</th>
<th align="right">Bird</th>
<th align="right">Other</th>
<th align="right">Fish</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Hancock</td>
<td align="left">nonadult</td>
<td align="right">0.09</td>
<td align="right">0.05</td>
<td align="right">0.07</td>
<td align="right">0.25</td>
<td align="right">0.54</td>
</tr>
<tr class="even">
<td align="left">Hancock</td>
<td align="left">adult</td>
<td align="right">0.02</td>
<td align="right">0.07</td>
<td align="right">0.14</td>
<td align="right">0.19</td>
<td align="right">0.57</td>
</tr>
<tr class="odd">
<td align="left">Ocklawaha</td>
<td align="left">nonadult</td>
<td align="right">0.60</td>
<td align="right">0.08</td>
<td align="right">0.01</td>
<td align="right">0.05</td>
<td align="right">0.26</td>
</tr>
<tr class="even">
<td align="left">Ocklawaha</td>
<td align="left">adult</td>
<td align="right">0.25</td>
<td align="right">0.19</td>
<td align="right">0.03</td>
<td align="right">0.07</td>
<td align="right">0.46</td>
</tr>
<tr class="odd">
<td align="left">Trafford</td>
<td align="left">nonadult</td>
<td align="right">0.52</td>
<td align="right">0.09</td>
<td align="right">0.04</td>
<td align="right">0.17</td>
<td align="right">0.18</td>
</tr>
<tr class="even">
<td align="left">Trafford</td>
<td align="left">adult</td>
<td align="right">0.19</td>
<td align="right">0.20</td>
<td align="right">0.11</td>
<td align="right">0.20</td>
<td align="right">0.30</td>
</tr>
<tr class="odd">
<td align="left">George</td>
<td align="left">nonadult</td>
<td align="right">0.41</td>
<td align="right">0.01</td>
<td align="right">0.03</td>
<td align="right">0.09</td>
<td align="right">0.45</td>
</tr>
<tr class="even">
<td align="left">George</td>
<td align="left">adult</td>
<td align="right">0.14</td>
<td align="right">0.02</td>
<td align="right">0.08</td>
<td align="right">0.10</td>
<td align="right">0.66</td>
</tr>
</tbody>
</table>
<hr />
<p>Since the table of numbers are hard to see, visual inspection is something we can do.</p>
<pre class="r"><code>ggplot(melt(tabl,id.vars=c(&quot;lake&quot;,&quot;size&quot;)))+geom_point()+aes(x=variable,y=value,color=size)+facet_wrap(~lake)</code></pre>
<p><img src="09_GLM_Multinomial_files/figure-html/unnamed-chunk-26-1.png" width="80%" style="display: block; margin: auto;" /> This plot highlights the food types where there is discrepancy between the adults and non-adults.</p>
<hr />
</div>
<div id="section-radar-plot" class="section level3">
<h3>Radar plot</h3>
<p>By adding <code>coord_polar()+ geom_polygon(fill=NA)</code> you can get a radar plot.</p>
<pre class="r"><code>ggplot(melt(tabl,id.vars=c(&quot;lake&quot;,&quot;size&quot;)))+geom_point()+aes(x=variable,y=value,color=size,group=size)+facet_wrap(~lake)+ coord_polar()+ geom_polygon(fill=NA)</code></pre>
<p><img src="09_GLM_Multinomial_files/figure-html/unnamed-chunk-27-1.png" width="80%" style="display: block; margin: auto;" /></p>
<hr />
</div>
<div id="section-model-checks" class="section level3">
<h3>Model checks</h3>
<ul>
<li>We can check the fit of the model using the binned residual plots.</li>
</ul>
<pre class="r"><code>py&lt;-predict(gator_fit,type=&quot;response&quot;)
gatordf&lt;-as.data.frame(gator)
pr &lt;-data.frame(gatordf[,colnames(py)]/rowSums(gatordf[,colnames(py)])-py)
par(mfrow=c(1,5))
for(i in 1:5) binnedplot(py[,i],pr[,i])</code></pre>
<p><img src="09_GLM_Multinomial_files/figure-html/unnamed-chunk-28-1.png" width="95%" style="display: block; margin: auto;" /></p>
<hr />
</div>
</div>
<div id="section-ordinal-catergorial-outcome" class="section level2">
<h2>Ordinal Catergorial Outcome</h2>
<div id="section-ordered-caterogical-variable" class="section level3">
<h3>Ordered Caterogical variable</h3>
<ul>
<li>Although we can use the baseline logit model for any categorical data, when there is ordering in the response categories, one should try to take that into account.</li>
<li>Some examples of such categorical outcome are
<ul>
<li>Likert scale: agree, moderately agree, neutral, moderately disagree, disagree</li>
<li>Opinion poll: support, don’t know, against</li>
<li>number of star on a restaurant website</li>
</ul></li>
<li>It is similar to fitting logistic regressions as in the nominal multinomial regression case, however the difference is that neighboring categories have some predefined relationships. Therefore, what one would term as a success and failure may depend on the problem and because of that there are multiple flavors of the ordinal logistic models.
<ul>
<li>Cumulative logit model (most popular)</li>
<li>Adjacent categories logit model</li>
<li>Continuation ratio logit model</li>
</ul></li>
<li>We will focus on the cumulative logit model so if anything, try to understand the essence of the model.</li>
</ul>
<hr />
</div>
<div id="section-cumulative-logit" class="section level3">
<h3>Cumulative logit</h3>
<ul>
<li>Let <span class="math inline">\(y_i\)</span> be response for subject <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(y_i = j\)</span> means <span class="math inline">\(y_{ij}=1\)</span> and <span class="math inline">\(y_{ik}=0\)</span> for <span class="math inline">\(k\neq j\)</span> for <span class="math inline">\(c\)</span> indicators. <span class="math display">\[P(y_i\leq j)=\pi_{i1}+\cdots+\pi_{ij}\]</span></li>
<li><p>Cumulative logit: <span class="math display">\[\begin{align}
logit(P(y_i\leq j))&amp;=\log\frac{P(y_i\leq j)}{1-P(y_i\leq j)}\\
&amp;=\log\frac{\pi_{i1}+\cdots+\pi_{ij}}{\pi_{i(j+1)}+\cdots+\pi_{ic}},j=1,\dots, c-1
\end{align}\]</span></p></li>
<li>If you look only at a particular <span class="math inline">\(j\)</span>, <span class="math inline">\(logit(P(y_i\leq j))\)</span> is a logistic regression model with categories 1 to <span class="math inline">\(j\)</span> as success and <span class="math inline">\(j+1\)</span> to <span class="math inline">\(c\)</span> as failures.</li>
<li><p>We can combine all <span class="math inline">\(j-1\)</span> logistic regression into a parsimonious model. <span class="math display">\[\begin{align}
logit(P(y_i\leq j))= \alpha_j + \mathbf{X}_i\boldsymbol{\beta},j=1,\dots, c-1
\end{align}\]</span> <img src="09_GLM_Multinomial_files/figure-html/unnamed-chunk-29-1.png" width="80%" style="display: block; margin: auto;" /></p></li>
</ul>
<hr />
<ul>
<li>Cumulative odds ratio <span class="math display">\[\begin{align}
&amp;logit(P(y_i\leq j|\mathbf{x}_i=\mathbf{u}))-logit(P(y_i\leq j|\mathbf{x}_i=\mathbf{v}))\\
&amp;=\log\frac{P(y_i\leq j|\mathbf{x}_i=\mathbf{u})/P(y_i&gt; j|\mathbf{x}_i=\mathbf{u})}{P(y_i\leq j|\mathbf{x}_i=\mathbf{v})/P(y_i&gt; j|\mathbf{x}_i=\mathbf{v})}\\
&amp;=(\mathbf{u}-\mathbf{v})\boldsymbol{\beta}
\end{align}\]</span></li>
<li>Odds that <span class="math inline">\(y_i\leq j\)</span> at <span class="math inline">\(\mathbf{x}_i=\mathbf{u}\)</span> are <span class="math inline">\((\mathbf{u}-\mathbf{v})\boldsymbol{\beta}\)</span> times the odds at <span class="math inline">\(\mathbf{x}_i=\mathbf{v}\)</span></li>
</ul>
<hr />
</div>
<div id="section-proportional-odds-model" class="section level3">
<h3>Proportional odds model</h3>
<ul>
<li><p>Special case of cumulative logit model <span class="math display">\[\begin{align}
\frac{P(y_i\leq j)}{P(y_i&gt; j)}&amp;= exp(\alpha_j + x_{i1}\beta_1+ x_{i2}\beta_2+\cdots + x_{ip}\beta_p ),j=1,\dots, c-1
\end{align}\]</span></p></li>
<li>Every unit increase in <span class="math inline">\(x_{i1}\)</span> odds of <span class="math inline">\(y_i\leq j\)</span> gets a multiplicative increase of <span class="math inline">\(exp(\beta_1)\)</span>.<br />
</li>
<li>This is true for all <span class="math inline">\(j\)</span>.</li>
<li><p>This property of common effect for all the cumulative probability is referred to as proportional odds.</p></li>
</ul>
<hr />
</div>
<div id="section-latent-variable-formulation" class="section level3">
<h3>Latent variable formulation</h3>
<ul>
<li>Let <span class="math inline">\(z_i\)</span> denote underlying latent variable for subject <span class="math inline">\(i\)</span>.</li>
<li>Suppose <span class="math inline">\(z_i\)</span> has CDF <span class="math inline">\(G(\alpha_{j}-\mu_i)\)</span> where <span class="math inline">\(\mu_i=\mathbf{x}_i\boldsymbol{\beta}\)</span>.</li>
<li>Cutpoints <span class="math inline">\(-\infty=\alpha_0&lt;\alpha_1&lt;\cdots &lt;\alpha_c = \infty\)</span></li>
<li>We observe <span class="math display">\[y_i = j \mbox{ if } \alpha_{j-1} \leq z_i \leq \alpha_{j}\]</span></li>
<li>Then <span class="math display">\[P(y_i\leq j)=P(z_i\leq \alpha_{j})=G(\alpha_{j}-\mu_i)=G(\alpha_{j}-\mathbf{x}_i\boldsymbol{\beta})\]</span></li>
<li>The linear predictor <span class="math inline">\(\alpha_{j}-\mathbf{x}_i\boldsymbol{\beta}\)</span> instead of <span class="math inline">\(\alpha_{j}+\mathbf{x}_i\boldsymbol{\beta}\)</span>.</li>
</ul>
<p><img src="09_GLM_Multinomial_files/figure-html/unnamed-chunk-30-1.png" width="50%" style="display: block; margin: auto;" /></p>
<hr />
</div>
<div id="section-fitting" class="section level3">
<h3>fitting</h3>
<p><span class="math display">\[\begin{align}
\prod^N_{i=1}\left(\prod^c_{j=1}\pi_{ij}^{y_{ij}}\right)
&amp;=\prod^N_{i=1}\left(\prod^c_{j=1}[P(y_i\leq j)-P(y_i\leq j-1)]^{y_{ij}}\right)
\end{align}\]</span></p>
<p><span class="math display">\[L(\alpha,\beta)=\sum^N_{i=1}\sum^c_{j=1}y_{ij}\log[G(\alpha_{j}-\mathbf{x}_i\boldsymbol{\beta})-G(\alpha_{j-1}-\mathbf{x}_i\boldsymbol{\beta})]\]</span></p>
<ul>
<li>Likelihood equations are for <span class="math inline">\(\beta\)</span>s <span class="math display">\[\frac{\partial L(\alpha,\beta)}{\partial \beta_k} =\sum^N_{i=1}\sum^c_{j=1}y_{ij}x_{ik}\frac{g(\alpha_{j}-\mathbf{x}_i\boldsymbol{\beta})-g(\alpha_{j-1}-\mathbf{x}_i\boldsymbol{\beta})}{G(\alpha_{j}-\mathbf{x}_i\boldsymbol{\beta})-G(\alpha_{j-1}-\mathbf{x}_i\boldsymbol{\beta})}=0\]</span></li>
<li><p>and for <span class="math inline">\(\alpha\)</span> <span class="math display">\[\frac{\partial L(\alpha,\beta)}{\partial \alpha_k} =\sum^N_{i=1}\sum^c_{j=1}y_{ij}\frac{\delta_{jk}g(\alpha_{j}-\mathbf{x}_i\boldsymbol{\beta})-\delta_{(j-1)k}g(\alpha_{j-1}-\mathbf{x}_i\boldsymbol{\beta})}{G(\alpha_{j}-\mathbf{x}_i\boldsymbol{\beta})-G(\alpha_{j-1}-\mathbf{x}_i\boldsymbol{\beta})}=0\]</span></p></li>
<li><p>Newton-Raphson method or Fisher scoring to solve.</p></li>
</ul>
<hr />
</div>
<div id="section-ordered-logits-in-r" class="section level3">
<h3>Ordered logits in R</h3>
<ul>
<li>Two packages</li>
<li><code>MASS::polr</code> uses Model 3 parametrization (GH p.122)</li>
<li><code>VGAM::vglm(,family=cumulative)</code></li>
</ul>
<hr />
</div>
<div id="section-adjacent-categories-logit-model" class="section level3">
<h3>Adjacent categories logit model</h3>
<ul>
<li>Alternative to cumulative odds model is to consider ratios of probabilities for successive categories <span class="math display">\[\frac{\pi_{i1}}{\pi_{i2}},\frac{\pi_{i2}}{\pi_{i3}},\cdots, \frac{\pi_{i(c-1)}}{\pi_{ic}}\]</span></li>
<li>Adjacent categories logit model <span class="math display">\[\log\frac{\pi_{ij}}{\pi_{i(j+1)}}=\mathbf{x}_i\boldsymbol{\beta}_j\]</span></li>
<li>If we simplify to <span class="math display">\[\log\frac{\pi_{ij}}{\pi_{i(j+1)}}=\beta_{0j}+\beta_{1}x_1+\cdots + \beta_{p-1}x_{p-1}\]</span> the effect of each explanatory variable is assumed to be same for all adjacent pairs of categories.</li>
</ul>
<hr />
</div>
<div id="section-continuation-ratio-logit-model" class="section level3">
<h3>Continuation ratio logit model</h3>
<ul>
<li><p>Alternative to cumulative odds model is to consider ratios of probabilities for successive categories <span class="math display">\[\frac{\pi_{i1}}{\pi_{i2}},\frac{\pi_{i1}+\pi_{i2}}{\pi_{i3}},\cdots, \frac{\pi_{i1}+\cdots+\pi_{i(c-1)}}{\pi_{ic}}\]</span> or <span class="math display">\[\frac{\pi_{i1}}{\pi_{i2}+\cdots+\pi_{ic}},
\frac{\pi_{i2}}{\pi_{i3}+\cdots+\pi_{ic}},\cdots +\frac{\pi_{i(c-1)}}{\pi_{ic}}\]</span></p></li>
<li><p>Continuation ratio logit model</p></li>
</ul>
<p><span class="math display">\[\log\left(\frac{\pi_{ij}}{\pi_{i(j+1)}+\cdots+\pi_{ic}}\right)=\mathbf{x}_i\boldsymbol{\beta}_j\]</span></p>
<ul>
<li>Models the odds of the response being in category <span class="math inline">\(j\)</span> that is <span class="math inline">\(\alpha_{j-1} &lt; z_i &lt; \alpha_{j}\)</span> conditioned on <span class="math inline">\(\alpha_{j-1} &lt;z_i\)</span></li>
</ul>
<hr />
</div>
</div>
<div id="section-example-car-preferences" class="section level2">
<h2>[Example] Car preferences</h2>
<div id="section-car-preferences-air-conditioning-and-power-steering" class="section level3">
<h3>Car preferences (air conditioning and power steering)</h3>
<ul>
<li><span class="citation">[@dobson2008introduction]</span> 50 subjects in each of the 6 categories (2 gender and 3 age groups) were asked</li>
<li>How important is air conditioning and power steering?
<ul>
<li><code>1</code>: No/Little</li>
<li><code>2</code>: Important</li>
<li><code>3</code>: Very important</li>
</ul></li>
</ul>
<pre class="r"><code>Car_preferences &lt;- fread(&quot;Car_preferences.csv&quot;)
Car_preferences</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["sex"],"name":[1],"type":["chr"],"align":["left"]},{"label":["age"],"name":[2],"type":["chr"],"align":["left"]},{"label":["response"],"name":[3],"type":["chr"],"align":["left"]},{"label":["frequency"],"name":[4],"type":["int"],"align":["right"]}],"data":[{"1":"women","2":"18-23","3":"no/little","4":"26"},{"1":"women","2":"18-23","3":"important","4":"12"},{"1":"women","2":"18-23","3":"very important","4":"7"},{"1":"women","2":"24-40","3":"no/little","4":"9"},{"1":"women","2":"24-40","3":"important","4":"21"},{"1":"women","2":"24-40","3":"very important","4":"15"},{"1":"women","2":"> 40","3":"no/little","4":"5"},{"1":"women","2":"> 40","3":"important","4":"14"},{"1":"women","2":"> 40","3":"very important","4":"41"},{"1":"men","2":"18-23","3":"no/little","4":"40"},{"1":"men","2":"18-23","3":"important","4":"17"},{"1":"men","2":"18-23","3":"very important","4":"8"},{"1":"men","2":"24-40","3":"no/little","4":"17"},{"1":"men","2":"24-40","3":"important","4":"15"},{"1":"men","2":"24-40","3":"very important","4":"12"},{"1":"men","2":"> 40","3":"no/little","4":"8"},{"1":"men","2":"> 40","3":"important","4":"15"},{"1":"men","2":"> 40","3":"very important","4":"18"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<ul>
<li>Here is the visualization of the data</li>
</ul>
<p><img src="09_GLM_Multinomial_files/figure-html/unnamed-chunk-33-1.png" width="90%" style="display: block; margin: auto;" /></p>
<hr />
<ul>
<li>Same information on a frequency scale <img src="09_GLM_Multinomial_files/figure-html/unnamed-chunk-34-1.png" width="90%" style="display: block; margin: auto;" /></li>
</ul>
<p>What you can see is that there is large difference across the age groups There is slight difference between the gender for each age group suggesting that interaction between gender and age is not too large.</p>
</div>
<div id="section-model" class="section level3">
<h3>Model</h3>
<ul>
<li>We will fit a proportional odds model <span class="math display">\[\log\left(\frac{\pi_{2}+\pi_{3}}{\pi_{1}}\right)=\beta_1x_{men}+\beta_2x_{24-40}+\beta_3x_{40over}-\beta_{12}\]</span></li>
</ul>
<p><span class="math display">\[\log\left(\frac{\pi_{3}}{\pi_{1}+\pi_{2}}\right)=\beta_1x_{men}+\beta_2x_{24-40}+\beta_3x_{40over}-\beta_{23}\]</span></p>
<hr />
<ul>
<li>We can do this several ways but we’ll use <code>polr</code> so that we are consistent with the Gelman and Hill book.</li>
</ul>
<pre class="r"><code>car_polr&lt;- polr(response_f~sex_m+age_f,weights=frequency,
                data=Car_preferences)
round(summary(car_polr)$coef,2)</code></pre>
<pre><code>## 
## Re-fitting to get Hessian</code></pre>
<pre><code>##                          Value Std. Error t value
## sex_mmen                 -0.58       0.23   -2.55
## age_f24-40                1.15       0.28    4.13
## age_f&gt; 40                 2.23       0.29    7.66
## no/little|important       0.04       0.23    0.19
## important|very important  1.65       0.26    6.47</code></pre>
<pre><code>## 
## Re-fitting to get Hessian</code></pre>
<ul>
<li>The fitted models are</li>
</ul>
<p><span class="math display">\[\log\left(\frac{\hat{\pi}_{2}+\hat{\pi}_{3}}{\hat{\pi}_{1}}\right)=-0.04+-0.58x_{men}+1.15x_{24-40}+2.23x_{40over}\]</span></p>
<p><span class="math display">\[\log\left(\frac{\hat{\pi}_{3}}{\hat{\pi}_{1}+\hat{\pi}_{2}}\right)=-1.65+-0.58x_{men}+1.15x_{24-40}+2.23x_{40over}\]</span></p>
</div>
<div id="section-plotting-the-predicted-probability" class="section level3">
<h3>Plotting the predicted probability</h3>
<ul>
<li><p>We can visualize the result by plotting the predicted probability.</p></li>
<li><p>Stacked barplots are nice but it does not highlight details.</p></li>
</ul>
<pre class="r"><code>predx&lt;- expand.grid(sex_m=c(&quot;women&quot;,&quot;men&quot;),age_f=c(&quot;18-23&quot;,&quot;24-40&quot;,&quot;&gt; 40&quot;))
predy&lt;-predict(car_polr,newdata=predx,type = &quot;p&quot;)
ggplot(melt(cbind(predx,predy),id.vars = c(&quot;sex_m&quot;,&quot;age_f&quot;)))+
  geom_bar(stat=&quot;identity&quot;)+aes(x=age_f,y=value, fill=variable)+
  facet_grid(~sex_m)</code></pre>
<p><img src="09_GLM_Multinomial_files/figure-html/unnamed-chunk-37-1.png" width="95%" style="display: block; margin: auto;" /></p>
<ul>
<li>Line chart misses the proportionality component of the outcome but it is easier to see the discrepancy with the initial EDA plot.</li>
</ul>
<pre class="r"><code>ggplot(melt(cbind(predx,predy),id.vars = c(&quot;sex_m&quot;,&quot;age_f&quot;)))+
  geom_line()+aes(x=variable,y=value,group=age_f, color=age_f)+
  facet_grid(~sex_m)</code></pre>
<p><img src="09_GLM_Multinomial_files/figure-html/unnamed-chunk-38-1.png" width="95%" style="display: block; margin: auto;" /></p>
<hr />
</div>
<div id="section-confidence-interval" class="section level3">
<h3>Confidence Interval</h3>
<p>As with all GLM you can use the profile likelihood CI or the Wald CI.</p>
<pre class="r"><code>round(confint(car_polr),2)</code></pre>
<pre><code>## Waiting for profiling to be done...</code></pre>
<pre><code>## 
## Re-fitting to get Hessian</code></pre>
<pre><code>##            2.5 % 97.5 %
## sex_mmen   -1.02  -0.13
## age_f24-40  0.61   1.70
## age_f&gt; 40   1.67   2.81</code></pre>
<pre class="r"><code>round(confint.default(car_polr),2)</code></pre>
<pre><code>## 
## Re-fitting to get Hessian</code></pre>
<pre><code>##            2.5 % 97.5 %
## sex_mmen   -1.02  -0.13
## age_f24-40  0.60   1.69
## age_f&gt; 40   1.66   2.80</code></pre>
<pre class="r"><code>1-pchisq(deviance(car_polr),df.residual(car_polr))</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>car_polr&lt;- polr(response_f~sex_m+age_f,weights=frequency,data=Car_preferences)
residpolr&lt;-(model.matrix(~response_f-1,Car_preferences)-car_polr$fitted.values)
predx2&lt;- expand.grid(age_f=c(&quot;18-23&quot;,&quot;24-40&quot;,&quot;&gt; 40&quot;),sex_m=c(&quot;women&quot;,&quot;men&quot;))
predy2&lt;-predict(car_polr,newdata=predx2,type = &quot;p&quot;)</code></pre>
</div>
<div id="section-model-choice" class="section level3">
<h3>model choice</h3>
<ul>
<li>Do we have strong evidence to add the interaction term? The visual inspection did see slight possibility of gender and age interacting but the effect was not too large.</li>
</ul>
<pre class="r"><code>fit&lt;-polr(response_f~sex_m+age_f,weights=frequency,data=Car_preferences)
fit2&lt;-polr(response_f~sex_m*age_f,weights=frequency,data=Car_preferences)
pchisq(deviance(fit)-deviance(fit2), df=df.residual(fit)-df.residual(fit2), lower.tail=FALSE)</code></pre>
<pre><code>## [1] 0.3374261</code></pre>
<pre class="r"><code>AIC(fit);AIC(fit2)</code></pre>
<pre><code>## [1] 591.2956</code></pre>
<pre><code>## [1] 593.1227</code></pre>
</div>
<div id="section-model-check" class="section level3">
<h3>Model check</h3>
<ul>
<li>We should always check the residuals for any signs of misfit.</li>
</ul>
<pre class="r"><code>residr&lt;-dcast(Car_preferences2, sex_m  +age_f~response_f, value.var = &quot;freq&quot;)[,3:5]-predy2
par(mfrow=c(1,3))
for(i in 1:3) binnedplot(predy2[,i],residr[,i])</code></pre>
<p><img src="09_GLM_Multinomial_files/figure-html/unnamed-chunk-42-1.png" width="95%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#vglm(response_f~sex_m+age_f,weights=frequency,data=Car_preferences,family=cumulative(parallel=TRUE))</code></pre>
<hr />
</div>
<div id="section-interpreting-the-model" class="section level3">
<h3>Interpreting the model</h3>
<ul>
<li><p>fitted models <span class="math display">\[\begin{align}
\log\left(\frac{\hat{\pi}_{1}}{\hat{\pi}_{2}+\hat{\pi}_{3}}\right)&amp;=0.04+(-0.58)x_{men}+
1.15x_{24-40}+2.23x_{40over}\\
\log\left(\frac{\hat{\pi}_{1}+\hat{\pi}_{2}}{\hat{\pi}_{3}}\right)&amp;=1.65+(-0.58)x_{men}+
1.15x_{24-40}+2.23x_{40over}
\end{align}\]</span></p></li>
<li><p>For a female, age 18-23, <span class="math inline">\(x_{men}=0\)</span>, <span class="math inline">\(x_{24-40}=0\)</span> and <span class="math inline">\(x_{40over}=0\)</span></p></li>
</ul>
<p><span class="math display">\[\log\left(\frac{\hat{\pi}_{1}}{\hat{\pi}_{2}+\hat{\pi}_{3}}\right)=0.0435371\]</span> <span class="math display">\[\log\left(\frac{\hat{\pi}_{1}+\hat{\pi}_{2}}{\hat{\pi}_{3}}\right)=1.6549745\]</span></p>
<ul>
<li><p>If we solve for <span class="math inline">\(\hat{\pi}_{1}\)</span>,<span class="math inline">\(\hat{\pi}_{2}\)</span>, and <span class="math inline">\(\hat{\pi}_{3}\)</span> under <span class="math inline">\(\hat{\pi}_{1}+\hat{\pi}_{2}+\hat{\pi}_{3}=1\)</span> we get <span class="math inline">\(\hat{\pi}_{1}=0.51\)</span>, <span class="math inline">\(\hat{\pi}_{2}=0.33\)</span>, and <span class="math inline">\(\hat{\pi}_{3}=0.16\)</span>.</p></li>
<li><p>Or we can use <code>fitted</code> function.</p></li>
</ul>
<hr />
<pre class="r"><code>cbind(Car_preferences[,list(sex_m,age_f)],fitted(car_polr))[seq(1,18,by=3),]</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["sex_m"],"name":[1],"type":["fctr"],"align":["left"]},{"label":["age_f"],"name":[2],"type":["fctr"],"align":["left"]},{"label":["no/little"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["important"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["very important"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"women","2":"18-23","3":"0.5108826","4":"0.3286797","5":"0.16043777"},{"1":"women","2":"24-40","3":"0.2490730","4":"0.3752352","5":"0.37569186"},{"1":"women","2":"> 40","3":"0.1007497","4":"0.2587618","5":"0.64048855"},{"1":"men","2":"18-23","3":"0.6501647","4":"0.2528518","5":"0.09698344"},{"1":"men","2":"24-40","3":"0.3711383","4":"0.3761309","5":"0.25273073"},{"1":"men","2":"> 40","3":"0.1662146","4":"0.3334706","5":"0.50031477"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<div id="section-references" class="section level2">
<h2>References</h2>

<script type="application/shiny-prerendered" data-context="server-start">
knitr::opts_chunk$set(echo = TRUE,  fig.width=5.656,fig.height=4,fig.align="center",
                      out.width="95%",dev="CairoPNG")
knitr::knit_hooks$set(mysize = function(before, options, envir) {
  if (before) 
    return(options$size)
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>
 <!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["localforage"]},{"type":"character","attributes":{},"value":["1.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/localforage"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["localforage.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["htmlwidgets"]},{"type":"character","attributes":{},"value":["1.5.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["www"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["htmlwidgets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["htmlwidgets"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.5.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["quiz-binding"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["htmlwidgets"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["quiz.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/bootstrap.min.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["localforage"]},{"type":"character","attributes":{},"value":["1.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/localforage"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["localforage.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["slickquiz"]},{"type":"character","attributes":{},"value":["1.5.20"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["htmlwidgets/lib/slickquiz"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/slickQuiz.js"]},{"type":"character","attributes":{},"value":["css/slickQuiz.css","css/slickQuizTutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98]}},"value":[{"type":"character","attributes":{},"value":["abind","AER","arm","assertthat","backports","base","boot","Cairo","car","carData","cellranger","coda","colorspace","compiler","crayon","curl","data.table","datasets","digest","dplyr","ellipsis","evaluate","forcats","foreign","Formula","ggplot2","glue","graphics","grDevices","grid","gridExtra","gtable","haven","highr","hms","htmltools","htmlwidgets","httpuv","jsonlite","knitr","labeling","later","lattice","lazyeval","learnr","lifecycle","lme4","lmtest","magrittr","markdown","MASS","Matrix","methods","mime","minqa","munsell","nlme","nloptr","nnet","openxlsx","pacman","pillar","pkgconfig","plyr","promises","purrr","R6","RColorBrewer","Rcpp","readxl","reshape2","rio","rlang","rmarkdown","rprojroot","sandwich","scales","shiny","splines","stats","stats4","stringi","stringr","survival","tibble","tidyr","tidyselect","tools","utils","vctrs","VGAM","withr","xfun","xtable","yaml","zeallot","zip","zoo"]},{"type":"character","attributes":{},"value":["1.4-5","1.2-7","1.10-1","0.2.1","1.1.4","3.6.1","1.3-22","1.5-10","3.0-3","3.0-2","1.1.0","0.19-3","1.4-1","3.6.1","1.3.4","4.2","1.12.2","3.6.1","0.6.21","0.8.3","0.3.0","0.14","0.4.0","0.8-71","1.2-3","3.2.1","1.3.1","3.6.1","3.6.1","3.6.1","2.3","0.3.0","2.1.1","0.8","0.5.1","0.3.6","1.5.1","1.5.2","1.6","1.25","0.3","0.8.0","0.20-38","0.2.2","0.9.2.1","0.1.0","1.1-21","0.9-37","1.5","1.1","7.3-51.4","1.2-17","3.6.1","0.7","1.2.4","0.5.0","3.1-140","1.2.1","7.3-12","4.1.0.1","0.5.1","1.4.2","2.0.3","1.8.4","1.0.1","0.3.2","2.4.0","1.1-2","1.0.2","1.3.1","1.4.3","0.5.16","0.4.0","1.15","1.3-2","2.5-1","1.0.0","1.3.2","3.6.1","3.6.1","3.6.1","1.4.3","1.4.0","2.44-1.1","2.1.3","1.0.0","0.2.5","3.6.1","3.6.1","0.2.0","1.1-1","2.1.2","0.9","1.8-4","2.2.0","0.1.0","2.0.4","1.8-6"]}]}]}
</script>
<!--/html_preserve-->
</div>

</div> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h2 class="title toc-ignore" style="display:none;">Multinomial Regression</h2>
<h4 class="author"><em>Masanao Yajima</em></h4>
<h4 class="date"><em>October 13, 2018</em></h4>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</div> <!-- bandContent page -->
</div> <!-- pageContent band -->




<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>

</html>
